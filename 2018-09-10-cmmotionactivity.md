---
title: CMMotionActivity
author: Mattt
translator: Bei Li
category: Cocoa
excerpt: >
  å¦‚ä»Šçš„ iPhone éƒ½æœ‰ç€ä¸€æ•´å¥—ä¼ æ„Ÿå™¨ï¼ŒåŒ…æ‹¬ç›¸æœºã€æ°”å‹è®¡ã€é™€èºä»ªã€ç£å¼ºè®¡å’ŒåŠ é€Ÿè§„ã€‚å’Œäººç±»ä¸€æ ·ï¼Œå®ƒä»¬ä½¿ç”¨ä¸åŒæ„Ÿè§‰ä¿¡æ¯çš„ç»„åˆæ¥ç¡®å®šå…¶ä½ç½®å’Œæœå‘ï¼Œé€šå¸¸å’Œæˆ‘ä»¬è‡ªèº«çš„ç”Ÿç‰©åŠ›å­¦è¿‡ç¨‹éå¸¸ç›¸ä¼¼ã€‚
status:
  swift: 4.2
---

Humans perceive self-motion using a combination of
sensory information from their visual, proprioceptive, and vestibular systems.
Of these,
the primary determination is made by the vestibular system,
comprising the
<dfn>semicircular canals</dfn>,
which sense changes in rotation,
and the <dfn>otoliths</dfn>,
which are sensitive to horizontal and vertical forces.

äººç±»é€šè¿‡ç»„åˆè§†è§‰ã€æœ¬ä½“æ„Ÿè§‰å’Œå‰åº­ç³»ç»Ÿå¾—åˆ°çš„æ„Ÿè§‰ä¿¡æ¯æ¥å¯Ÿè§‰è‡ªèº«çš„è¿åŠ¨ã€‚å…¶ä¸­å‰åº­ç³»ç»Ÿèµ·åˆ°ä¸»è¦ä½œç”¨ï¼Œå‰åº­ç³»ç»Ÿç”±æ„Ÿè§‰æ—‹è½¬çš„<dfn>åŠè§„ç®¡</dfn>å’Œå¯¹æ°´å¹³ä¸å‚ç›´å—åŠ›æ•æ„Ÿçš„<dfn>è€³çŸ³</dfn>æ„æˆã€‚

Today's iPhones are packed with a full complement of sensors that includes
cameras, barometers, gyroscopes, magnetometers, and accelerometers.
Like humans, they use permutations of different sensory information
to make determinations about their position and orientation,
often by means quite similar to our own biomechanical processes.

å¦‚ä»Šçš„ iPhone éƒ½æœ‰ç€ä¸€æ•´å¥—ä¼ æ„Ÿå™¨ï¼ŒåŒ…æ‹¬ç›¸æœºã€æ°”å‹è®¡ã€é™€èºä»ªã€ç£å¼ºè®¡å’ŒåŠ é€Ÿè§„ã€‚å’Œäººç±»ä¸€æ ·ï¼Œå®ƒä»¬ä½¿ç”¨ä¸åŒæ„Ÿè§‰ä¿¡æ¯çš„ç»„åˆæ¥ç¡®å®šå…¶ä½ç½®å’Œæœå‘ï¼Œé€šå¸¸å’Œæˆ‘ä»¬è‡ªèº«çš„ç”Ÿç‰©åŠ›å­¦è¿‡ç¨‹éå¸¸ç›¸ä¼¼ã€‚

Making sense of sensory inputs ---
no matter their origin ---
is challenging.
There's just so much information to consider.
(Heck, it took our species a few million years to get that right,
and we're still confused by newfangled inventions like
elevators, planes, and roller coasters.)

è®©æ„Ÿè§‰è¾“å…¥æœ‰æ„ä¹‰â€”â€”ä¸ç®¡å®ƒä»¬æ˜¯ä»å“ªé‡Œæ¥çš„â€”â€”æ˜¯éå¸¸æœ‰æŒ‘æˆ˜æ€§çš„ã€‚éœ€è¦è€ƒè™‘çš„ä¿¡æ¯å®åœ¨å¤ªå¤šäº†ã€‚ï¼ˆè§é¬¼ï¼Œæˆ‘ä»¬è¿™ä¸ªç§æ—èŠ±äº†å°å‡ ç™¾ä¸‡å¹´æ‰æå®šè¿™ä»¶äº‹ï¼Œç„¶è€Œæˆ‘ä»¬è¿˜æ˜¯ä¼šè¢«åƒç”µæ¢¯ã€é£æœºå’Œè¿‡å±±è½¦è¿™äº›æ–°å¥‡çš„å‘æ˜å¼„æ™•ã€‚ï¼‰

After several major OS releases and hardware versions,
Apple devices have become adroit at differentiating between different
means of locomotion.
But before you run off and try to write your own implementation,
stop and consider using the built-in APIs discussed in this week's article.

ç»è¿‡å‡ ä¸ªç‰ˆæœ¬çš„ç³»ç»Ÿä¸ç¡¬ä»¶æ›´æ–°ï¼Œè‹¹æœçš„è®¾å¤‡å˜å¾—æ“…é•¿äºåŒºåˆ†è¿åŠ¨çš„ä¸åŒæ„ä¹‰ã€‚åœ¨ä½ è·‘å»å°è¯•è‡ªå·±å®ç°å‰ï¼Œåœä¸‹æ¥è€ƒè™‘ä¸€ä¸‹ä½¿ç”¨è¿™å‘¨æ–‡ç« ä¸­è®¨è®ºçš„å†…ç½® APIã€‚

---

On iOS and watchOS,
`CMMotionActivityManager` takes raw sensor data from the device
and tells you (to what degree of certainty)
whether the user is currently moving,
and if they're walking, running, biking, or driving in an automobile.

åœ¨ iOS å’Œ watchOS ä¸Šï¼Œ`CMMotionActivityManager` å¤„ç†è®¾å¤‡ä¸­ä¼ æ„Ÿå™¨çš„åŸå§‹æ•°æ®å¹¶å‘Šè¯‰ä½ ï¼ˆæœ‰å¤šç¡®å®šï¼‰ç”¨æˆ·æ˜¯å¦æ­£åœ¨ç§»åŠ¨ï¼Œå’Œç”¨æˆ·æ˜¯åœ¨è¡Œèµ°ã€è·‘æ­¥ã€éª‘è¡Œæˆ–è€…å¼€è½¦ã€‚

To use this API,
you create an activity manager
and start listening for activity updates
using the `startActivityUpdates` method.
Each time the device updates the motion activity,
it executes the specified closure,
passing a `CMMotionActivity` object.

è¦ä½¿ç”¨è¿™ä¸ª APIï¼Œé¦–å…ˆåˆ›å»ºä¸€ä¸ªæ´»åŠ¨ç®¡ç†å™¨ï¼Œç„¶åä½¿ç”¨ `startActivityUpdates` æ–¹æ³•æ¥å¼€å§‹ç›‘å¬æ´»åŠ¨æ›´æ–°ã€‚æ¯å½“è®¾å¤‡æ›´æ–°äº†è¿åŠ¨ç›¸å…³æ´»åŠ¨ï¼Œå®ƒå°±ä¼šæ‰§è¡ŒæŒ‡å®šçš„é—­åŒ…ï¼Œå¹¶ä¼ å…¥ä¸€ä¸ª `CMMotionActivity` å¯¹è±¡ã€‚

```swift
let manager = CMMotionActivityManager()
manager.startActivityUpdates(to: .main) { (activity) in
    guard let activity = activity else {
        return
    }

    var modes: Set<String> = []
    if activity.walking {
        modes.insert("ğŸš¶â€")
    }

    if activity.running {
        modes.insert("ğŸƒâ€")
    }

    if activity.cycling {
        modes.insert("ğŸš´â€")
    }

    if activity.automotive {
        modes.insert("ğŸš—")
    }

    print(modes.joined(separator: ", "))
}
```

`CMMotionActivityManager` is provided by the Core Motion framework.
Devices that support Core Motion are equipped with a motion coprocessor.
By using dedicated hardware,
the system can offload all sensor processing from the CPU
and minimize energy usage.

`CMMotionActivityManager` ç”± Core Motion æ¡†æ¶æä¾›ã€‚æ”¯æŒ Core Motion çš„è®¾å¤‡éƒ½è£…å¤‡äº†ä¸€ä¸ªè¿åŠ¨è¾…åŠ©å¤„ç†å™¨ã€‚é€šè¿‡ä½¿ç”¨ä¸“ç”¨ç¡¬ä»¶ï¼Œç³»ç»Ÿå¯ä»¥å°†æ‰€æœ‰ä¼ æ„Ÿå™¨å¤„ç†å·¥ä½œä» CPU ä¸Šç§»é™¤æ‰ï¼Œå¹¶å‡å°‘ç”µé‡çš„ä½¿ç”¨ã€‚

The first of the _M-series_ coprocessors was the M7,
which arrived in September 2013 with the iPhone 5S.
This coincided with the release of iOS 7 and the Core Motion APIs.

ç¬¬ä¸€æ¬¾ **M ç³»åˆ—**è¾…åŠ©å¤„ç†å™¨æ˜¯ M7ï¼Œåœ¨ 2013 å¹´ä¹æœˆä¸ iPhone 5S ä¸€åŒé¢ä¸–ã€‚iOS 7 å’Œ Core Motion API ä¹Ÿä¸æ­¤åŒæ—¶å‘å¸ƒã€‚

## Feature Drivers
## å¸æœºåŠŸèƒ½

Possibly the most well-known use of motion activities is
["Do Not Disturb While Driving"](https://support.apple.com/en-us/HT208090),
added in iOS 11.
Automotive detection got much better with the introduction of this feature.

å¯èƒ½è¿åŠ¨æ´»åŠ¨æœ€å¹¿ä¸ºäººçŸ¥çš„ä½¿ç”¨æ˜¯ iOS 11 ä¸­æ–°å¢çš„[ã€Œé©¾é©¶å‹¿æ‰°ã€](https://support.apple.com/zh-cn/HT208090)åŠŸèƒ½ã€‚è¿™é¡¹åŠŸèƒ½æ¨å‡ºåï¼Œå¯¹äºå¼€è½¦çš„æ£€æµ‹å˜å¥½äº†å¾ˆå¤šã€‚

> At low speeds, it's hard to distinguish automobile travel from other means
> using accelerometer data alone.
> Although we can only speculate as to how this works,
> it's possible that the iPhone uses magnetometer data from the device compass.
> Because cars and other vehicles are often enclosed in metal,
> electromagnetic flux is reduced.

> åœ¨é€Ÿåº¦æ¯”è¾ƒä½çš„æƒ…å†µä¸‹ï¼Œåªä½¿ç”¨åŠ é€Ÿè§„çš„æ•°æ®æ˜¯å¾ˆéš¾åŒºåˆ†é©¾è½¦è¡Œé©¶å’Œå…¶ä»–æ´»åŠ¨çš„ã€‚æˆ‘ä»¬åªèƒ½çŒœæµ‹ï¼Œæœ‰å¯èƒ½ iPhone æ˜¯ä½¿ç”¨ç£å¼ºè®¡çš„æ•°æ®æ¥å®ç°è¿™é¡¹åŠŸèƒ½çš„ã€‚å› ä¸ºæ±½è½¦å’Œå…¶ä»–æœºåŠ¨è½¦è¾†é€šå¸¸è¢«é‡‘å±å›´ç»•ç€ï¼Œç”µç£é€šé‡ä¼šå‡å°‘ã€‚

Beyond safety concerns,
some apps might change their behavior
according to the current mode of transportation.
For example,
a delivery service app might relay changes in motion activity to a server
to recalculate estimated ETA or change the UI to communicate
that the courier has parked their vehicle and are now approaching by foot.

é™¤äº†å®‰å…¨ç›¸å…³çš„è€ƒè™‘ï¼Œä¸€äº›åº”ç”¨å¯èƒ½ä¼šæ ¹æ®å½“å‰çš„äº¤é€šæ¨¡å¼æ”¹å˜è¡Œä¸ºã€‚æ¯”å¦‚ï¼Œä¸€ä¸ªå¿«é€’åº”ç”¨å¯èƒ½ä¼šå‘é€è¿åŠ¨æ´»åŠ¨æ”¹å˜åˆ°æœåŠ¡å™¨æ¥é‡æ–°è®¡ç®—é¢„è®¡åˆ°è¾¾æ—¶é—´ï¼Œæˆ–è€…æ›´æ–° UI æ¥è¡¨æ˜å¿«é€’å‘˜å·²ç»åœä¸‹äº†è½¦å­ï¼Œæ­£åœ¨èµ°è·¯æ¥è¿‘ã€‚

## Traveling Without Moving
## ä¸åŠ¨åœ°ç§»åŠ¨

`CMMotionActivity` has Boolean properties
for each of the different types of motion
as well as one for whether the device is stationary.
This seems counter-intuitive,
as logic dictates that
you can either be walking or driving a car at a given moment,
but not both.

`CMMotionActivity` å¯¹æ¯ç§è¿åŠ¨ç±»å‹éƒ½æœ‰ä¸€ä¸ªå¸ƒå°”å€¼å±æ€§ï¼Œå¹¶ä¸”è¿˜æœ‰è¿˜æœ‰ä¸€ä¸ªè®¾å¤‡æ˜¯å¦åœæ»çš„å±æ€§ã€‚è¿™ä¼¼ä¹è¿åç›´è§‰ï¼Œé€»è¾‘ä¸Šæ¥è¯´ä½ åœ¨åŒä¸€æ—¶é—´åªèƒ½æ­¥è¡Œæˆ–è€…å¼€è½¦ï¼Œä½†ä¸èƒ½ä¸€èµ·è¿›è¡Œã€‚

This point is clarified by the [`CMMotionActivity` documentation](https://developer.apple.com/documentation/coremotion/cmmotionactivity):

å…³äºè¿™ä¸€ç‚¹åœ¨ [`CMMotionActivity` çš„æ–‡æ¡£](https://developer.apple.com/documentation/coremotion/cmmotionactivity)ä¸­æœ‰æ¾„æ¸…ï¼š

> The motion-related properties of this class are not mutually exclusive.
> In other words, it is possible for more than one of the
> motion-related properties to contain the value `true`.
> For example, if the user was **driving in a car**
> and the car stopped at a red light,
> the update event associated with that change in motion would have both
> the `cycling` and `stationary` properties set to true.

> æœ¬ç±»ä¸­å…³äºè¿åŠ¨çš„å±æ€§å¹¶ä¸æ˜¯äº’ç›¸æ’æ–¥çš„ã€‚æ¢å¥è¯è¯´ï¼Œæœ‰å¯èƒ½æœ‰å¤šä¸ªè¿åŠ¨ç›¸å…³å±æ€§çš„å€¼ä¸º `true`ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œå¦‚æœç”¨æˆ·åœ¨**é©¾é©¶ä¸€è¾†è½¦**ï¼Œç„¶ååœ¨çº¢ç¯å‰åœäº†ä¸‹æ¥ï¼Œå¯¹äºè¿™ä¸ªäº‹æƒ…ä¸­è¿åŠ¨ç›¸å…³çš„æ›´æ–°äº‹ä»¶ä¼šå°† `cycling` å’Œ `stationary` å±æ€§éƒ½è®¾ä¸ºçœŸã€‚
>
> æ–‡æ¡£åŸæ–‡ï¼š
>
> The motion-related properties of this class are not mutually exclusive.
> In other words, it is possible for more than one of the
> motion-related properties to contain the value `true`.
> For example, if the user was **driving in a car**
> and the car stopped at a red light,
> the update event associated with that change in motion would have both
> the `cycling` and `stationary` properties set to true.

Wait, did I say clarified?
I meant... whatever the opposite is.
(I'm pretty sure this should be `automotive`)
Fortunately, the header docs tell us more about what we might expect.
Here are some concrete examples of how this API behaves in different situations:

ç­‰ç­‰ï¼Œæˆ‘åˆšæ‰è¯´äº†æ¾„æ¸…ï¼Ÿæˆ‘çš„æ„æ€æ˜¯â€¦â€¦åæ­£ä¸æ˜¯å’Œè¿™ä¸ªæ–‡æ¡£è¿™æ ·ã€‚ï¼ˆæˆ‘å¾ˆç¡®å®šè¿™ä¸ªä¾‹å­åº”è¯¥æ˜¯ `automotive`ï¼‰å¹¸å¥½ï¼Œå¤´æ–‡ä»¶çš„æ–‡æ¡£æœ‰æ¯”æˆ‘ä»¬æƒ³çŸ¥é“çš„æ›´å¤šä¿¡æ¯ã€‚ä¸‹é¢æœ‰ä¸€äº›è¿™ä¸ª API åœ¨ä¸åŒæƒ…å†µä¸‹å…·ä½“çš„ä¾‹å­ï¼š

**Scenario 1**:
You're in a car stopped at a red light

**åœºæ™¯ 1**ï¼šä½ åœ¨ä¸€è¾†åœåœ¨çº¢ç¯å‰çš„è½¦é‡Œ

| ğŸš¶â€ `walking` | ğŸƒâ€ `running` | ğŸš´â€`cycling` | ğŸš— `automotive` | ğŸ›‘ `stationary` |
| ------------- | ------------- | ------------ | --------------- | --------------- |
| `false`       | `false`       | `false`      | `true`          | `true`          |

**Scenario 2**:
You're in a moving vehicle

**åœºæ™¯ 2**ï¼šä½ åœ¨ä¸€è¾†ç§»åŠ¨ä¸­çš„æœºåŠ¨è½¦é‡Œ

| ğŸš¶â€ `walking` | ğŸƒâ€ `running` | ğŸš´â€`cycling` | ğŸš— `automotive` | ğŸ›‘ `stationary` |
| ------------- | ------------- | ------------ | --------------- | --------------- |
| `false`       | `false`       | `false`      | `true`          | `false`         |

**Scenario 3**:
The device is in motion, but you're neither walking nor in a moving vehicle

**åœºæ™¯ 3**ï¼šè®¾å¤‡æ­£åœ¨è¿åŠ¨ï¼Œä½†ä½ æ²¡æœ‰åœ¨èµ°è·¯ä¹Ÿæ²¡æœ‰åœ¨æœºåŠ¨è½¦è¾†ä¸Š

| ğŸš¶â€ `walking` | ğŸƒâ€ `running` | ğŸš´â€`cycling` | ğŸš— `automotive` | ğŸ›‘ `stationary` |
| ------------- | ------------- | ------------ | --------------- | --------------- |
| `false`       | `false`       | `false`      | `false`         | `false`         |

**Scenario 4**:
You're a world-famous detective, who,
in the process of chasing a suspect down the corridors of a moving train,
has reached the last car and has stopped to look around
to surmise where they're hiding
_(perhaps that conspicuous, person-sized box in the corner?)_

**åœºæ™¯ 4**ï¼šä½ æ˜¯ä¸€ä¸ªåä¾¦æ¢ï¼Œåœ¨ä¸€è¾†è¡Œé©¶ä¸­çš„ç«è½¦ä¸Šçš„èµ°å»Šé‡Œè¿½é€å«Œç–‘çŠ¯ï¼Œè·‘åˆ°äº†æœ€åä¸€èŠ‚è½¦å¢å¹¶åœä¸‹æ¥å››å¤„æŸ¥çœ‹çŒœæµ‹ä»–ä»¬è—åœ¨å“ªã€‚**ï¼ˆå¯èƒ½åœ¨è§’è½é‡Œé‚£ä¸ªå¯ç–‘ã€ä¸€äººå¤§å°çš„ç®±å­é‡Œï¼Ÿï¼‰**

| ğŸš¶â€ `walking` | ğŸƒâ€ `running` | ğŸš´â€`cycling` | ğŸš— `automotive` | ğŸ›‘ `stationary` | ğŸ•µï¸â€ğŸ‡§ğŸ‡ª `poirot` |
| ------------- | ------------- | ------------ | --------------- | --------------- | --------------- |
| `false`       | `true`        | `false`      | `true`          | `true`          | `true`          |

(We're actually not sure what would happen in that last scenario...)

ï¼ˆæˆ‘ä»¬å®é™…ä¸Šå¹¶ä¸ç¡®å®šæœ€åä¸€ä¸ªåœºæ™¯ä¼šå‘ç”Ÿä»€ä¹ˆâ€¦â€¦ï¼‰

The overall guidance from the documentation is that
you should treat `stationary` to be orthogonal from
all of the other `CMMotionActivity` properties
and that you should be prepared to handle all other combinations.

æ€»çš„æ¥è¯´è¿™ä¸ªæ–‡æ¡£çš„å¤§æ„æ˜¯ï¼Œä½ åº”è¯¥è®¤ä¸º `stationary` å’Œ `CMMotionActivity` ä¸­å…¶ä»–å±æ€§æ˜¯æ­£äº¤çš„ï¼Œå¹¶ä¸”ä½ åº”è¯¥å‡†å¤‡å¥½å¤„ç†æ‰€æœ‰çš„ç»„åˆæƒ…å†µã€‚

Each `CMMotionActivity` object also includes a `confidence` property
with possible values of `.low`, `.medium`, and `.high`.
Unfortunately, not much information is provided by the documentation
about what any of these values mean, or how they should be used.
As is often the case,
an empirical approach is recommended;
test your app in the field to
see when different confidence values are produced
and use that information to determine the correct behavior for your app.

æ¯ä¸ª `CMMotionActivity` å¯¹è±¡è¿˜åŒ…æ‹¬äº†ä¸€ä¸ªå…¶å€¼å¯èƒ½ä¸º `.low`ã€`.medium` æˆ– `.high` çš„ `confidence` å±æ€§ã€‚ä¸å¹¸çš„æ˜¯ï¼Œæ–‡æ¡£æ²¡æœ‰æä¾›å¤šå°‘å…³äºè¿™äº›å€¼çš„æœ‰ç”¨ä¿¡æ¯ï¼Œæˆ–è€…å¦‚ä½•ä½¿ç”¨ã€‚å¯¹äºè¿™ç§æƒ…å†µï¼Œæ¨èä½¿ç”¨ä¸€ç§ç»éªŒæ€§çš„æ–¹æ³•ï¼šå®é™…æµ‹è¯•ä½ çš„åº”ç”¨ï¼Œè§‚å¯Ÿä¸åŒæƒ…å†µä¸‹å‡ºç°çš„ `confidence` å€¼ï¼Œä½¿ç”¨è¿™äº›ä¿¡æ¯æ¥ä¿®æ­£åº”ç”¨çš„è¡Œä¸ºã€‚

## Combining with Location Queries
## ä¸ä½ç½®æŸ¥è¯¢ç»„åˆä½¿ç”¨

Depending on your use case,
it might make sense to coordinate Core Motion readings with
[Core Location](https://nshipster.com/core-location-in-ios-8/) data.

æ ¹æ®ä½ çš„å®é™…æƒ…å†µï¼Œç»„åˆä½¿ç”¨ Core Motion å’Œ [Core Location](https://nshipster.cn/core-location-in-ios-8/) æ•°æ®å¯èƒ½æ˜¯æœ‰æ„ä¹‰çš„ã€‚

You can combine changes in location over time
with low-confidence motion activity readings
to increase accuracy.
Here are some general guidelines for typical ranges of speeds
for each of the modes of transportation:

ä½ å¯ä»¥ç»„åˆä¸€æ®µæ—¶é—´çš„ä½ç½®å˜åŒ–å’ŒæŠŠæ¡æ¯”è¾ƒä½çš„è¿åŠ¨æ´»åŠ¨æ•°æ®æ¥æé«˜ç²¾ç¡®åº¦ã€‚è¿™é‡Œæœ‰ä¸€äº›ä¸åŒç§»åŠ¨æ–¹å¼å…¸å‹é€Ÿåº¦èŒƒå›´çš„æŒ‡å¯¼æ–¹é’ˆï¼š

- Walking speeds typically peak at 2.5 meters per second (5.6 mph, 9 km/h)
- æ­¥è¡Œé€Ÿåº¦é€šå¸¸æœ€é«˜èƒ½è¾¾åˆ° 2.5 ç±³æ¯ç§’ï¼ˆ5.6 mph, 9 km/hï¼‰
- Running speeds range from 2.5 to 7.5 meters per second (5.6 â€“ 16.8 mph, 9 â€“ 27 km/h)
- è·‘æ­¥é€Ÿåº¦èŒƒå›´ä» 2.5 åˆ° 7.5 ç±³æ¯ç§’ï¼ˆ5.6 â€“ 16.8 mph, 9 â€“ 27 km/hï¼‰
- Cycling speeds range from 3 to 12 meters per second (6.7 â€“ 26.8 mph, 10.8 â€“ 43.2 km/h)
- éª‘è¡Œé€Ÿåº¦èŒƒå›´ä» 3 åˆ° 12 ç±³æ¯ç§’ï¼ˆ6.7 â€“ 26.8 mph, 10.8 â€“ 43.2 km/hï¼‰
- Automobile speeds can exceed 100 meters per second (220 mph, 360 km/h)
- æ±½è½¦çš„é€Ÿåº¦å¯ä»¥è¶…è¿‡ 100 ç±³æ¯ç§’ï¼ˆ220 mph, 360 km/hï¼‰

Alternatively, you might use location data to change the UI
depending on whether the current location is in a body of water.

æˆ–è€…ï¼Œä½ å¯èƒ½ä¼šä½¿ç”¨ä½ç½®æ•°æ®æ¥æ”¹å˜ UIï¼Œå–å†³äºç°åœ¨çš„ä½ç½®æ˜¯å¦åœ¨ä¸€ç‰‡æ°´åŸŸã€‚

```swift
if currentLocation.intersects(waterRegion) {
    if activity.walking {
        print("ğŸŠâ€")
    } else if activity.automotive {
        print("ğŸš¢")
    }
}
```

However, location data should only be consulted if absolutely necessary ---
and when you do, it should be done sparingly,
such as by monitoring for only significant location changes.
Reason being,
location data requires turning on the GPS and/or cellular radio,
which are both energy intensive.

ç„¶è€Œï¼Œä½ç½®æ•°æ®åº”è¯¥åªåœ¨ç»å¯¹å¿…è¦çš„æ—¶å€™å†æŸ¥è¯¢â€”â€”å½“ä½ éœ€è¦æŸ¥è¯¢æ—¶ï¼Œä¹Ÿåº”è¯¥å°½é‡å°‘çš„æŸ¥è¯¢ï¼Œæ¯”å¦‚åªæ£€æµ‹æ˜¾è‘—çš„ä½ç½®æ”¹å˜ã€‚è¿™æ ·çš„åŸå› æ˜¯ï¼Œè·å–ä½ç½®æ•°æ®è¦æ±‚ä½¿ç”¨ GPS ä¸”/æˆ–ç§»åŠ¨ç½‘ç»œï¼Œå®ƒä»¬éƒ½éå¸¸è€—ç”µã€‚

---

`CMMotionActivityManager` is one of many great APIs in Core Motion
that you can use to build immersive, responsive apps.

`CMMotionActivityManager` æ˜¯ Core Motion é‡Œé‚£äº›å¥½ç”¨ API çš„å…¶ä¸­ä¸€ä¸ªï¼Œä½ å¯ä»¥ä½¿ç”¨å®ƒæ¥æ„é€ æ²‰æµ¸ã€ååº”çµæ•çš„åº”ç”¨ã€‚

If you haven't considered the potential of
incorporating device motion into your app
(or maybe haven't looked at Core Motion for a while),
you might be surprised at what's possible.

å¦‚æœä½ è¿˜æ²¡æœ‰è€ƒè™‘è¿‡å°†è®¾å¤‡è¿åŠ¨ä¿¡æ¯çº³å…¥åº”ç”¨çš„å¯èƒ½æ€§ï¼ˆæˆ–è€…å¯èƒ½ä½ å¾ˆä¹…æ²¡æœ‰å…³æ³¨è¿‡ Core Motionï¼‰ï¼Œä½ å¯èƒ½ä¼šè¢«å®ƒèƒ½åšåˆ°çš„äº‹æƒ…æƒŠè®¶åˆ°ã€‚
